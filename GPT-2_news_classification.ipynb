{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "574e5963",
      "metadata": {
        "id": "574e5963"
      },
      "source": [
        "# Question 2:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "1a1d27a9",
      "metadata": {
        "id": "1a1d27a9"
      },
      "outputs": [],
      "source": [
        "# !pip3 install torch==1.10.2+cu113 torchvision==0.11.3+cu113 torchaudio==0.10.2+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
        "# !pip3 install pandas\n",
        "# !pip3 install numpy\n",
        "# !pip3 install sklearn\n",
        "# !pip3 install tqdm\n",
        "# !pip3 install transformers\n",
        "# !pip install newspaper3k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "e741e3d1",
      "metadata": {
        "id": "e741e3d1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from transformers import GPT2Model, GPT2Tokenizer\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "import newspaper\n",
        "import random\n",
        "import csv\n",
        "import langdetect\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-Cn8qwXUvsGp",
      "metadata": {
        "id": "-Cn8qwXUvsGp"
      },
      "source": [
        "# 1."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3b5ebf5",
      "metadata": {
        "id": "c3b5ebf5"
      },
      "source": [
        "## Scraping technological and political news using newspaper3k package and assigning label to them as technology and political."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "wi40ORNhv0AD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi40ORNhv0AD",
        "outputId": "f7cd3d1b-a0c8-4c87-bf57-0989aba72dae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping https://www.techradar.com/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.techradar.com/feeds\n",
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.techradar.com/feed\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping https://www.theverge.com/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.theverge.com/feeds\n",
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.theverge.com/feed\n",
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.theverge.com/rss\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error processing article: Article `download()` failed with 403 Client Error: Forbidden for url: https://www.fortnite.com/news/race-without-limits-with-rocket-racing-in-fortnite on URL https://www.fortnite.com/news/race-without-limits-with-rocket-racing-in-fortnite\n",
            "Error processing article: Article `download()` failed with ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')) on URL https://www.thegamer.com/neil-newbon-wins-best-performance-at-the-game-awards-2023/\n",
            "Error processing article: Article `download()` failed with 403 Client Error: Forbidden for url: https://genius.com/Nobuo-uematsu-one-winged-angel-final-fantasy-vii-lyrics on URL https://genius.com/Nobuo-uematsu-one-winged-angel-final-fantasy-vii-lyrics\n",
            "Scraping https://www.wired.com/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.wired.com/feeds/\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping https://www.tomshardware.com/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.tomshardware.com/rss\n",
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.tomshardware.com/feed\n",
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.tomshardware.com/feeds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping https://www.politico.com/...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.politico.com/%7B%7Bpermalink%7D%7D\n",
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.politico.com/%7B%7BflagURL%7D%7D\n",
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.politico.com/feed\n",
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.politico.com/feeds\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scraping https://www.nytimes.com/section/politics...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.nytimes.com/feeds\n",
            "CRITICAL:newspaper.network:[REQUEST FAILED] 404 Client Error: Not Found for url: https://www.nytimes.com/feed\n"
          ]
        }
      ],
      "source": [
        "conn = sqlite3.connect('news_articles.db')\n",
        "c = conn.cursor()\n",
        "\n",
        "c.execute('CREATE TABLE IF NOT EXISTS articles (id INTEGER PRIMARY KEY AUTOINCREMENT, title TEXT, text TEXT, label TEXT)')\n",
        "\n",
        "tech_websites = ['https://www.techradar.com/', 'https://www.theverge.com/', 'https://www.wired.com/',\n",
        "                 'https://www.tomshardware.com/']\n",
        "\n",
        "political_websites = ['https://www.politico.com/',\n",
        "                      'https://www.nytimes.com/section/politics']\n",
        "\n",
        "for website in tech_websites + political_websites:\n",
        "    print(f'Scraping {website}...')\n",
        "    paper = newspaper.build(website)\n",
        "    count = 0\n",
        "\n",
        "    for article in paper.articles:\n",
        "        if count == 200:\n",
        "            break\n",
        "        try:\n",
        "            article.download()\n",
        "            article.parse()\n",
        "            title = article.title\n",
        "            text = article.text\n",
        "            label = 'technology' if website in tech_websites else 'political'\n",
        "            c.execute(\"INSERT INTO articles (title, text, label) VALUES (?, ?, ?)\", (title, text, label))\n",
        "            count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing article: {str(e)}\")\n",
        "\n",
        "conn.commit()\n",
        "c.execute(\"SELECT title, text, label FROM articles WHERE label='technology' OR label='political'\")\n",
        "results = c.fetchall()\n",
        "\n",
        "random.shuffle(results)\n",
        "with open('news_dataset.csv', 'w', newline='') as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow(['text', 'label'])\n",
        "    for result in results:\n",
        "        writer.writerow([result[1], result[2]])\n",
        "\n",
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "FpLVNHgpvz9p",
      "metadata": {
        "id": "FpLVNHgpvz9p"
      },
      "outputs": [],
      "source": [
        "news_data = pd.read_csv('news_dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "d4Fxkfgbvz7k",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4Fxkfgbvz7k",
        "outputId": "fa127cd7-5b23-428b-829b-f9d58708baef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(724, 2)"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "news_data.shape\n",
        "# this data has 724 articles, so we need to filter out the political and technology news using our keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "sXm-99L_vz5g",
      "metadata": {
        "id": "sXm-99L_vz5g"
      },
      "outputs": [],
      "source": [
        "# drop missing values\n",
        "news_data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "WjPqAViLvz3J",
      "metadata": {
        "id": "WjPqAViLvz3J"
      },
      "outputs": [],
      "source": [
        "# Defining the keywords for each category to filter them\n",
        "technology_keywords = ['AI', 'GPT-4', 'GPT', 'Transformers', 'Gemini', 'OpenAI']\n",
        "political_keywords = ['Obama', 'Trump', 'Biden', 'Joe Biden', 'Republican', 'Democracy', 'president']\n",
        "\n",
        "technology_articles = news_data[news_data['label'] == 'technology']\n",
        "technology_articles = technology_articles[technology_articles['text'].str.contains('|'.join(technology_keywords), case=False)]\n",
        "\n",
        "political_articles = news_data[news_data['label'] == 'political']\n",
        "political_articles = political_articles[political_articles['text'].str.contains('|'.join(political_keywords), case=False)]\n",
        "\n",
        "# Sample 312 articles from each technology\n",
        "technology_sample = technology_articles.sample(312, random_state=42)\n",
        "result_df = pd.concat([technology_sample, political_articles])\n",
        "result_df = result_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "result_df.to_csv('news_data.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "39xOIE64vz0s",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39xOIE64vz0s",
        "outputId": "457f3acc-ca66-408d-ed36-3b6205b9c71d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "technology    312\n",
              "political     140\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y_t96lgGwKrd",
      "metadata": {
        "id": "Y_t96lgGwKrd"
      },
      "source": [
        "Each article has around 1000+ words. There are 452 articles in total with two categories-technology and political(312 and 140 articles each). Let's check if the articles are in english or not for ease in pre-processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "194ae8ef",
      "metadata": {
        "id": "194ae8ef"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/news_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "O2SPzjJer2Or",
      "metadata": {
        "id": "O2SPzjJer2Or"
      },
      "outputs": [],
      "source": [
        "def detect_language(text):\n",
        "    try:\n",
        "        return langdetect.detect(text)\n",
        "    except:\n",
        "        return 'unknown'\n",
        "df['language'] = df['text'].apply(detect_language)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "Ip9o-UWUsEY2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip9o-UWUsEY2",
        "outputId": "c246071a-1769-4e70-df44-891d75b9194d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "en    448\n",
              "ja      4\n",
              "Name: language, dtype: int64"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.language.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "oBqn0YHSyDUw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBqn0YHSyDUw",
        "outputId": "2535e2a0-62b2-4760-cd4c-8519853b76d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "technology    312\n",
              "political     140\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "7aYv2Cypr7s4",
      "metadata": {
        "id": "7aYv2Cypr7s4"
      },
      "outputs": [],
      "source": [
        "df = df[df['language'] == 'en']\n",
        "df = df.drop(columns=['language'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "531e2aeb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "531e2aeb",
        "outputId": "5ab78d3c-ee86-4152-8850-6d70bbfe8940",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4611e498-228c-4bcd-af14-a5489b90c182\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Beeper says “fix coming soon” for its Android ...</td>\n",
              "      <td>technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>You could say that Fortnite is entering a new ...</td>\n",
              "      <td>technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>According to the IOC, eight Russian and three ...</td>\n",
              "      <td>political</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That partnership will be put to the test this ...</td>\n",
              "      <td>political</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Transcript\\n\\n[Pilot] Attention, passengers.\\n...</td>\n",
              "      <td>technology</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4611e498-228c-4bcd-af14-a5489b90c182')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4611e498-228c-4bcd-af14-a5489b90c182 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4611e498-228c-4bcd-af14-a5489b90c182');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-70f688d3-1eea-4d25-aef9-6e45a22e41bd\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-70f688d3-1eea-4d25-aef9-6e45a22e41bd')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-70f688d3-1eea-4d25-aef9-6e45a22e41bd button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                                text       label\n",
              "0  Beeper says “fix coming soon” for its Android ...  technology\n",
              "1  You could say that Fortnite is entering a new ...  technology\n",
              "2  According to the IOC, eight Russian and three ...   political\n",
              "3  That partnership will be put to the test this ...   political\n",
              "4  Transcript\\n\\n[Pilot] Attention, passengers.\\n...  technology"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "id": "a9390985",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9390985",
        "outputId": "41c4b5ed-8c63-4295-e3f8-a9ba914262d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "technology    308\n",
              "political     140\n",
              "Name: label, dtype: int64"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.label.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OTbMy2HC2ZN8",
      "metadata": {
        "id": "OTbMy2HC2ZN8"
      },
      "source": [
        "There are 448 articles in total, and technology -308,\n",
        "political - 140 articles."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c8a45a7",
      "metadata": {
        "id": "2c8a45a7"
      },
      "source": [
        "## Preprocessing data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2f4c65cc",
      "metadata": {
        "id": "2f4c65cc"
      },
      "source": [
        "We  build a custom Dataset class to tokenize our news dataset and store them into containers for batch training.For GPT-2 we need to do padding to the left, because we need to use the last token for prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "id": "5b73b951",
      "metadata": {
        "id": "5b73b951"
      },
      "outputs": [],
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "labels = {\n",
        "    \"technology\": 0,\n",
        "    \"political\": 1\n",
        "         }\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.labels = [labels[label] for label in df['label']]\n",
        "        self.texts = [tokenizer(text,\n",
        "                                padding='max_length',\n",
        "                                max_length=128,\n",
        "                                truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "        return batch_texts, batch_y"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "z9-NVlzeysEW",
      "metadata": {
        "id": "z9-NVlzeysEW"
      },
      "source": [
        "# 2."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2b70d19",
      "metadata": {
        "id": "b2b70d19"
      },
      "source": [
        "## Split training-test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "aa8a30c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa8a30c1",
        "outputId": "e655a90a-7f99-4eda-cdc0-74ffef79f270"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "286 72 90\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "\n",
        "df_train, df_test = np.split(df.sample(frac=1, random_state=42), [int(0.8*len(df))])\n",
        "df_train, df_val = np.split(df_train.sample(frac=1, random_state=42), [int(0.8*len(df_train))])\n",
        "\n",
        "print(len(df_train), len(df_val), len(df_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J9NltFfS3QaF",
      "metadata": {
        "id": "J9NltFfS3QaF"
      },
      "source": [
        "We have 448 articles in total and we split the training and test by 80:20 and again split the training into train and val(80:20). So we have 286 articles for train , 72 for validation and 90 for test."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86YIuPLK4CGD",
      "metadata": {
        "id": "86YIuPLK4CGD"
      },
      "source": [
        "# 3."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14f92730",
      "metadata": {
        "id": "14f92730"
      },
      "source": [
        "# Fine tuning pre-trained model: GPT-2"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84f05f6b",
      "metadata": {
        "id": "84f05f6b"
      },
      "source": [
        "Adding a linear layer on top of GPT-2's 12 layers of decoders with its output dimension equals our number of categories(2 in this case)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "d9479c79",
      "metadata": {
        "id": "d9479c79"
      },
      "outputs": [],
      "source": [
        "class SimpleGPT2SequenceClassifier(nn.Module):\n",
        "    def __init__(self, hidden_size: int, num_classes:int ,max_seq_len:int, gpt_model_name:str):\n",
        "        super(SimpleGPT2SequenceClassifier,self).__init__()\n",
        "        self.gpt2model = GPT2Model.from_pretrained(gpt_model_name)\n",
        "        self.fc1 = nn.Linear(hidden_size*max_seq_len, num_classes)\n",
        "    def forward(self, input_id, mask):\n",
        "        gpt_out, _ = self.gpt2model(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
        "        batch_size = gpt_out.shape[0]\n",
        "        linear_output = self.fc1(gpt_out.view(batch_size,-1))\n",
        "        return linear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "7dc4a339",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dc4a339",
        "outputId": "2b190875-c862-4708-94ee-7f4310dfdc2d",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 143/143 [00:12<00:00, 11.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 1 | Train Loss:  0.472             | Train Accuracy:  0.671             | Val Loss:  0.164             | Val Accuracy:  0.861\n"
          ]
        }
      ],
      "source": [
        "def train(model, train_data, val_data, learning_rate, epochs):\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "        criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "        total_acc_train = 0\n",
        "        total_loss_train = 0\n",
        "\n",
        "        for train_input, train_label in tqdm(train_dataloader):\n",
        "            train_label = train_label.to(device)\n",
        "            mask = train_input['attention_mask'].to(device)\n",
        "            input_id = train_input[\"input_ids\"].squeeze(1).to(device)\n",
        "\n",
        "            model.zero_grad()\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "\n",
        "            batch_loss = criterion(output, train_label)\n",
        "            total_loss_train += batch_loss.item()\n",
        "\n",
        "            acc = (output.argmax(dim=1)==train_label).sum().item()\n",
        "            total_acc_train += acc\n",
        "\n",
        "            batch_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_acc_val = 0\n",
        "        total_loss_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            for val_input, val_label in val_dataloader:\n",
        "                val_label = val_label.to(device)\n",
        "                mask = val_input['attention_mask'].to(device)\n",
        "                input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "\n",
        "                batch_loss = criterion(output, val_label)\n",
        "                total_loss_val += batch_loss.item()\n",
        "\n",
        "                acc = (output.argmax(dim=1)==val_label).sum().item()\n",
        "                total_acc_val += acc\n",
        "\n",
        "            print(\n",
        "            f\"Epochs: {epoch_num + 1} | Train Loss: {total_loss_train/len(train_data): .3f} \\\n",
        "            | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n",
        "            | Val Loss: {total_loss_val / len(val_data): .3f} \\\n",
        "            | Val Accuracy: {total_acc_val / len(val_data): .3f}\")\n",
        "\n",
        "EPOCHS = 1\n",
        "model = SimpleGPT2SequenceClassifier(hidden_size=768, num_classes=2, max_seq_len=128, gpt_model_name=\"gpt2\")\n",
        "LR = 1e-5\n",
        "\n",
        "train(model, df_train, df_val, LR, EPOCHS)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ff5dea5",
      "metadata": {
        "id": "1ff5dea5"
      },
      "source": [
        "We train it for 1 epoch because GPT-2 is already a large model trained on lots of parameters and we acheive a good validation accuracy(0.861) by training on 1 epoch itself."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9fe4ba4",
      "metadata": {
        "id": "c9fe4ba4"
      },
      "source": [
        "Evaluate on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "e9413304",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9413304",
        "outputId": "22d10e61-0100-4dab-af74-31693557ca9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy:  0.867\n"
          ]
        }
      ],
      "source": [
        "def evaluate(model, test_data):\n",
        "    test = Dataset(test_data)\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "    if use_cuda:\n",
        "        model = model.cuda()\n",
        "    predictions_labels = []\n",
        "    true_labels = []\n",
        "    total_acc_test = 0\n",
        "    with torch.no_grad():\n",
        "        for test_input, test_label in test_dataloader:\n",
        "            test_label = test_label.to(device)\n",
        "            mask = test_input['attention_mask'].to(device)\n",
        "            input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "            output = model(input_id, mask)\n",
        "\n",
        "            acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "            total_acc_test += acc\n",
        "            true_labels += test_label.cpu().numpy().flatten().tolist()\n",
        "            predictions_labels += output.argmax(dim=1).cpu().numpy().flatten().tolist()\n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')\n",
        "    return true_labels, predictions_labels\n",
        "true_labels, pred_labels = evaluate(model, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "a6104415",
      "metadata": {
        "id": "a6104415"
      },
      "outputs": [],
      "source": [
        "# save trained model\n",
        "torch.save(model.state_dict(), \"./gpt2-text-classifier-model.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "afcc233b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afcc233b",
        "outputId": "9130afe3-60ea-4bcc-aa13-4fdb2436e7aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SimpleGPT2SequenceClassifier(\n",
              "  (gpt2model): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (fc1): Linear(in_features=98304, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load trained model\n",
        "model_new = SimpleGPT2SequenceClassifier(hidden_size=768, num_classes=2, max_seq_len=128, gpt_model_name=\"gpt2\")\n",
        "model_new.load_state_dict(torch.load(\"./gpt2-text-classifier-model.pt\"))\n",
        "model_new.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c487cf5",
      "metadata": {
        "id": "5c487cf5"
      },
      "source": [
        "# Predicting on new data from a different website to evaluate on the fine tuned model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "73c599d6",
      "metadata": {
        "id": "73c599d6"
      },
      "outputs": [],
      "source": [
        "example = \"\"\"\n",
        "U.S. chip giant Nvidia (NVDA.O) will discuss cooperation deals on semiconductors with Vietnamese tech companies and authorities in a meeting on Monday in Hanoi, an invitation letter to participants seen by Reuters showed.\n",
        "The southeast Asian country, which is home to large chip assembling factories including Intel's (INTC.O) biggest globally, is trying to expand into chip designing and possibly chip-making as trade tensions between the United States and China create opportunities for Vietnam in the strategic industry.\n",
        "\"\"\"\n",
        "lower = \" \".join(example.lower().split())\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "tokenizer.padding_side = \"left\"\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model_inp = tokenizer(lower, padding='max_length', max_length=128, truncation=True, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "f9319acd",
      "metadata": {
        "id": "f9319acd"
      },
      "outputs": [],
      "source": [
        "mask = model_inp['attention_mask'].cpu()\n",
        "input_id = model_inp[\"input_ids\"].squeeze(1).cpu()\n",
        "output = model_new(input_id, mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "f4de8a92",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4de8a92",
        "outputId": "0ae0140a-43d8-4bec-8c28-abf5a9c9e6b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.9295, 0.0705], grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prob = torch.nn.functional.softmax(output, dim=1)[0]\n",
        "prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "1ea88e42",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1ea88e42",
        "outputId": "0f793e40-6671-46cd-8fb2-601387ea3288"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'technology'"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels_map = {\n",
        "    0: \"technology\",\n",
        "    1: \"political\",\n",
        "         }\n",
        "pred = labels_map[output.argmax(dim=1).item()]\n",
        "pred"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sWJYP9u77Khm",
      "metadata": {
        "id": "sWJYP9u77Khm"
      },
      "source": [
        "Test Accuracy is 86.7 percent. We can improve this by scraping more news articles from different websites and increase the train size of the model. Additionally different pre-trained transformer models (including BERT, BART, RoBERTa) or a transformer model fine-tuned for news articles (in HuggingFace )can be used to see which one performs better on large training data and this use case.\n",
        "\n",
        "Another way would be to use different context of technological data and political data rather than just the news articles to make the model truly understand such aspects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "T09Qfk499bBj",
      "metadata": {
        "id": "T09Qfk499bBj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "pnyAXvwg9enj",
      "metadata": {
        "id": "pnyAXvwg9enj"
      },
      "source": [
        "# References:\n",
        "\n",
        "\n",
        "\n",
        "1.  Dataset created - https://drive.google.com/drive/folders/1SOezYpvKoHJj7dw_v8b_G6ZnEr-jZ5P3?usp=sharing\n",
        "2. https://huggingface.co/gpt2\n",
        "3.   https://discuss.huggingface.co/t/fine-tuning-gpt2-for-movie-script-generation-in-pytorch/23906/3\n",
        "4. https://github.com/haocai1992/GPT2-News-Classifier?tab=readme-ov-file\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28956609",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
